{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP2200/COMP6200 Practical Exercise (Week 12): Recommender Systems\n",
    "\n",
    "## School of Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEU Survey\n",
    "\n",
    "You have been invited to participate in a Learner Experience of Unit (LEU) survey for COMP2200/COMP6200-Data Science. You will have already received an individual email invitation and link to the survey. You can also access the survey on the 'Student Feedback Surveys' block of your iLearn homepage (not the unit homepage). Take some time to complete it now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prac Details\n",
    "\n",
    "This prac is almost definitely more than 2 hours in length. This is the first time we have done taught recommendation engines, so we don't know how much of the prac students will complete within 2 hours.\n",
    "\n",
    "Feel free to choose which sections are the most interesting to you. Let us know which parts you found useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "Choose your environment: either run locally with `uv` or use [Google Colab](https://colab.research.google.com/).\n",
    "\n",
    "1. **Local with `uv`**:\n",
    "   - Install `uv`:\n",
    "     - **MacOS/Linux**: `curl -LsSf https://astral.sh/uv/install.sh | sh`\n",
    "     - **Windows**: `powershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"`\n",
    "   - Create a folder for this practical (for example, `week12-prac`) and open a terminal in it.\n",
    "   - Set up your environment:\n",
    "     ```\n",
    "     uv init\n",
    "     uv add implicit pandas numpy matplotlib scipy scikit-learn\n",
    "     ```\n",
    "   - Launch Jupyter with `uv run --with jupyter jupyter lab` (or `... notebook`).\n",
    "\n",
    "2. **Google Colab**:\n",
    "   - Open Colab and create a new notebook.\n",
    "   - Install packages with `!pip install implicit pandas numpy matplotlib scipy scikit-learn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A --- Joke Recommender with Jester Dataset\n",
    "\n",
    "In this part, you'll build a joke recommendation system using the Jester dataset. Jester contains ratings of jokes from real users on a continuous scale from -10 (worst joke ever) to +10 (best joke ever). This is a classic example of **explicit feedback** --- users directly tell us their opinion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1. Import required libraries\n",
    "\n",
    "Import the necessary Python modules for this practical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A2. Load the Jester dataset\n",
    "\n",
    "Load the Jester dataset from the local file and examine its shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Jester dataset...\n",
      "Dataset loaded!\n",
      "Number of users: 24,983\n",
      "Number of jokes: 100\n",
      "\n",
      "Sample of raw data (99 means 'not rated'):\n",
      "     1      2      3      4     5     6     7     8      9      10   ...  \\\n",
      "0  -7.82   8.79  -9.66  -8.16 -7.52 -8.50 -9.85  4.17  -8.98  -4.76  ...   \n",
      "1   4.08  -0.29   6.36   4.37 -2.38 -9.66 -0.73 -5.34   8.88   9.22  ...   \n",
      "2  99.00  99.00  99.00  99.00  9.03  9.27  9.03  9.27  99.00  99.00  ...   \n",
      "3  99.00   8.35  99.00  99.00  1.80  8.16 -2.82  6.21  99.00   1.84  ...   \n",
      "4   8.50   4.61  -4.17  -5.39  1.36  1.60  7.04  4.61  -0.44   5.73  ...   \n",
      "\n",
      "     91     92     93     94     95     96     97     98     99     100  \n",
      "0   2.82  99.00  99.00  99.00  99.00  99.00  -5.63  99.00  99.00  99.00  \n",
      "1   2.82  -4.95  -0.29   7.86  -0.19  -2.14   3.06   0.34  -4.32   1.07  \n",
      "2  99.00  99.00  99.00   9.08  99.00  99.00  99.00  99.00  99.00  99.00  \n",
      "3  99.00  99.00  99.00   0.53  99.00  99.00  99.00  99.00  99.00  99.00  \n",
      "4   5.19   5.58   4.27   5.19   5.73   1.55   3.11   6.55   1.80   1.60  \n",
      "\n",
      "[5 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Jester dataset...\")\n",
    "jester_raw = pd.read_csv('jester-data-1.csv', header=None, usecols=range(1, 101))\n",
    "print(\"Dataset loaded!\")\n",
    "\n",
    "# Get dimensions\n",
    "n_users, n_jokes = jester_raw.shape\n",
    "print(f\"Number of users: {n_users:,}\")\n",
    "print(f\"Number of jokes: {n_jokes}\")\n",
    "print(f\"\\nSample of raw data (99 means 'not rated'):\")\n",
    "print(jester_raw.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A3. Explore the dataset statistics\n",
    "\n",
    "Convert from wide to long format using pandas `melt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings: 1,810,455\n",
      "Rating scale: -9.9 to 10.0\n",
      "Global mean rating: 0.88\n"
     ]
    }
   ],
   "source": [
    "# Convert from wide to long format\n",
    "# Columns are jokes (0-99), rows are users, 99 means \"not rated\"\n",
    "\n",
    "# Add user ID column from the index\n",
    "jester_raw['user'] = jester_raw.index\n",
    "\n",
    "ratings_df = jester_raw.melt(\n",
    "    id_vars='user',\n",
    "    var_name='item',\n",
    "    value_name='rating'\n",
    ")\n",
    "\n",
    "# Filter out missing ratings (99 means not rated)\n",
    "ratings_df = ratings_df[ratings_df['rating'] != 99]\n",
    "\n",
    "# Convert item to 0-indexed integers (columns are 1-100, need 0-99 for indexing)\n",
    "ratings_df['item'] = ratings_df['item'].astype(int) - 1\n",
    "\n",
    "# Print statistics\n",
    "n_ratings = len(ratings_df)\n",
    "\n",
    "print(f\"Number of ratings: {n_ratings:,}\")\n",
    "print(f\"Rating scale: {ratings_df['rating'].min():.1f} to {ratings_df['rating'].max():.1f}\")\n",
    "print(f\"Global mean rating: {ratings_df['rating'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the matrix sparsity (what percentage of cells are empty):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix sparsity: 27.5%\n"
     ]
    }
   ],
   "source": [
    "total_possible = n_users * n_jokes\n",
    "sparsity = 1 - (n_ratings / total_possible)\n",
    "print(f\"Matrix sparsity: {sparsity:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: The Jester dataset has about 27% sparsity. Typical movie ratings datasets (like MovieLens) have 93--95% sparsity. Why is Jester so much less sparse? What does this tell you about how the Jester data was collected compared to movie ratings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A4. Train a baseline model\n",
    "\n",
    "Let's start with a baseline: a simple model that always predicts the mean rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 1,809,455\n",
      "Test set: 1,000\n",
      "\n",
      "Baseline Results:\n",
      "  RMSE: 5.1996\n",
      "  MAE:  4.3595\n"
     ]
    }
   ],
   "source": [
    "# Split into train/test sets\n",
    "train_df, test_df = train_test_split(ratings_df, test_size=1000, random_state=42)\n",
    "\n",
    "print(f\"Training set: {len(train_df):,}\")\n",
    "print(f\"Test set: {len(test_df):,}\")\n",
    "\n",
    "# Train baseline model (always predicts mean rating)\n",
    "baseline = DummyRegressor(strategy='mean')\n",
    "baseline.fit(train_df[['user', 'item']], train_df['rating'])\n",
    "y_pred = baseline.predict(test_df[['user', 'item']])\n",
    "\n",
    "# Evaluate\n",
    "rmse_baseline = root_mean_squared_error(test_df['rating'], y_pred)\n",
    "mae_baseline = mean_absolute_error(test_df['rating'], y_pred)\n",
    "\n",
    "print(f\"\\nBaseline Results:\")\n",
    "print(f\"  RMSE: {rmse_baseline:.4f}\")\n",
    "print(f\"  MAE:  {mae_baseline:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A5. Train an SVD model\n",
    "\n",
    "SVD (Singular Value Decomposition) is a matrix factorization technique that finds latent factors for users and jokes. The idea is that each user and each joke can be represented as a vector in a lower-dimensional \"latent space\". Users and jokes that are similar will be close together in this space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create the user-item matrix\n",
    "\n",
    "First, create a user-item matrix from the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-item matrix shape: (24983, 100)\n"
     ]
    }
   ],
   "source": [
    "# Create user-item matrix from training data\n",
    "# Rows = users, columns = jokes, cells = ratings\n",
    "user_item_matrix = train_df.pivot_table(\n",
    "    index='user',\n",
    "    columns='item',\n",
    "    values='rating',\n",
    "    fill_value=0  # Fill missing ratings with 0\n",
    ")\n",
    "\n",
    "print(f\"User-item matrix shape: {user_item_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `pivot_table` operation converts our long-format dataframe (one row per rating) into a wide-format matrix where each row represents a user and each column represents a joke. Missing ratings are filled with 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Apply SVD decomposition\n",
    "\n",
    "Now apply SVD to decompose this matrix into user and item factors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User factors shape: (24983, 20)\n",
      "Item factors shape: (100, 20)\n"
     ]
    }
   ],
   "source": [
    "# Apply SVD using scikit-learn's TruncatedSVD\n",
    "# n_factors controls the dimensionality of the latent space\n",
    "# More factors = more expressive but risk of overfitting\n",
    "n_factors = 20\n",
    "\n",
    "svd_model = TruncatedSVD(n_components=n_factors, random_state=42)\n",
    "user_factors = svd_model.fit_transform(user_item_matrix)\n",
    "item_factors = svd_model.components_.T\n",
    "\n",
    "print(f\"User factors shape: {user_factors.shape}\")\n",
    "print(f\"Item factors shape: {item_factors.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD decomposes the user-item matrix into two smaller matrices: `user_factors` (users × latent factors) and `item_factors` (jokes × latent factors). Each user is now represented by 20 numbers, and each joke is represented by 20 numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Reconstruct the ratings matrix\n",
    "\n",
    "Reconstruct the full ratings matrix and make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted ratings matrix shape: (24983, 100)\n"
     ]
    }
   ],
   "source": [
    "# Reconstruct the full ratings matrix by multiplying user and item factors\n",
    "# Matrix multiplication: (users x factors) @ (factors x items) = (users x items)\n",
    "# This gives us predicted ratings for all user-item pairs\n",
    "predicted_ratings = user_factors @ item_factors.T\n",
    "\n",
    "print(f\"Predicted ratings matrix shape: {predicted_ratings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reconstructed matrix contains predicted ratings for every user-joke pair, even those we never observed in the training data. This is the power of collaborative filtering --- it can predict ratings for unseen user-joke combinations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Evaluate on test set\n",
    "\n",
    "Now evaluate the model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVD Results:\n",
      "  RMSE: 3.9943\n",
      "  MAE:  3.1234\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for our test set\n",
    "# For each test rating, look up the predicted value for that (user, item) pair\n",
    "test_users = test_df['user'].values\n",
    "test_items = test_df['item'].values\n",
    "svd_predictions = predicted_ratings[test_users, test_items]\n",
    "\n",
    "# Calculate error metrics\n",
    "rmse_svd = root_mean_squared_error(test_df['rating'], svd_predictions)\n",
    "mae_svd = mean_absolute_error(test_df['rating'], svd_predictions)\n",
    "\n",
    "print(f\"\\nSVD Results:\")\n",
    "print(f\"  RMSE: {rmse_svd:.4f}\")\n",
    "print(f\"  MAE:  {mae_svd:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the improvement over the baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Improvement over baseline: 23.2%\n"
     ]
    }
   ],
   "source": [
    "improvement = (1 - rmse_svd/rmse_baseline) * 100\n",
    "print(f\"\\nImprovement over baseline: {improvement:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: How much better is SVD than the baseline (predicting mean rating)? What does this tell you about patterns in humor preferences?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A6. Train a KNN model\n",
    "\n",
    "KNN (K-Nearest Neighbors) implements user-based collaborative filtering. The idea is simple: to predict what rating you'll give a joke, we find users similar to you and use their ratings to make a prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Build the KNN model\n",
    "\n",
    "First, build the KNN model to find similar users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global mean rating: 0.88\n"
     ]
    }
   ],
   "source": [
    "# Build KNN model on user vectors\n",
    "# Each user is represented by their ratings across all jokes\n",
    "k = 30  # How many similar users to consider\n",
    "knn_model = NearestNeighbors(n_neighbors=k+1, metric='cosine')\n",
    "knn_model.fit(user_item_matrix.values)\n",
    "\n",
    "# Calculate global mean from training data for fallback\n",
    "# We'll use this if we can't find similar users who rated an item\n",
    "global_mean = train_df['rating'].mean()\n",
    "print(f\"Global mean rating: {global_mean:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine similarity measures how similar two users are based on their rating patterns. The model will find the k=30 most similar users for any given user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Make predictions\n",
    "\n",
    "Now make predictions for each test rating by averaging similar users' ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made 1000 predictions\n"
     ]
    }
   ],
   "source": [
    "# Make predictions for each test rating\n",
    "knn_predictions = []\n",
    "\n",
    "for _, row in test_df.iterrows():\n",
    "    user_id = int(row['user'])\n",
    "    item_id = int(row['item'])\n",
    "\n",
    "    # Find this user's k nearest neighbors\n",
    "    user_vector = user_item_matrix.iloc[user_id].values.reshape(1, -1)\n",
    "    distances, neighbor_indices = knn_model.kneighbors(user_vector)\n",
    "\n",
    "    # Get ratings from neighbors for this specific joke\n",
    "    neighbor_ratings = []\n",
    "    for neighbor_idx in neighbor_indices[0][1:]:  # Skip user itself (first result)\n",
    "        rating = user_item_matrix.iloc[neighbor_idx, item_id]\n",
    "        if rating != 0:  # Only use actual ratings (0 means missing)\n",
    "            neighbor_ratings.append(rating)\n",
    "\n",
    "    # Predict as average of neighbor ratings, or global mean if no neighbors rated it\n",
    "    if len(neighbor_ratings) > 0:\n",
    "        knn_predictions.append(np.mean(neighbor_ratings))\n",
    "    else:\n",
    "        knn_predictions.append(global_mean)\n",
    "\n",
    "knn_predictions = np.array(knn_predictions)\n",
    "print(f\"Made {len(knn_predictions)} predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction algorithm works like this: For each test rating, we find similar users who also rated that joke, then average their ratings. If no similar users rated it, we fall back to the global mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Evaluate performance\n",
    "\n",
    "Evaluate the KNN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Results:\n",
      "  RMSE: 4.2209\n",
      "  MAE:  3.3024\n"
     ]
    }
   ],
   "source": [
    "# Calculate error metrics\n",
    "rmse_knn = root_mean_squared_error(test_df['rating'], knn_predictions)\n",
    "mae_knn = mean_absolute_error(test_df['rating'], knn_predictions)\n",
    "\n",
    "print(f\"KNN Results:\")\n",
    "print(f\"  RMSE: {rmse_knn:.4f}\")\n",
    "print(f\"  MAE:  {mae_knn:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A7. Try content-based filtering with TF-IDF\n",
    "\n",
    "So far we've used collaborative filtering (learning from user ratings). Now let's try content-based filtering (using the text of jokes).\n",
    "\n",
    "First, load the joke text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 jokes\n",
      "\n",
      "Sample joke:\n",
      "Joke 0: A man visits the doctor. The doctor says \"I have bad news for you.You have cancer and Alzheimer's disease\". The man replies \"Well,thank God I don't have cancer!\"\n"
     ]
    }
   ],
   "source": [
    "# Load joke text\n",
    "jokes_df = pd.read_csv('jester-jokes.csv')\n",
    "print(f\"Loaded {len(jokes_df)} jokes\")\n",
    "print(f\"\\nSample joke:\")\n",
    "print(f\"Joke {jokes_df.iloc[0]['joke_id']}: {jokes_df.iloc[0]['joke_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build TF-IDF vectors and compute joke similarities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF matrix shape: (100, 100)\n",
      "Joke similarity matrix shape: (100, 100)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Build TF-IDF vectors for jokes\n",
    "vectorizer = TfidfVectorizer(max_features=100, stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(jokes_df['joke_text'])\n",
    "\n",
    "print(f\"\\nTF-IDF matrix shape: {tfidf_matrix.shape}\")\n",
    "\n",
    "# Compute joke-to-joke similarity\n",
    "joke_similarity = cosine_similarity(tfidf_matrix)\n",
    "print(f\"Joke similarity matrix shape: {joke_similarity.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions using content-based filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making content-based predictions...\n",
      "\n",
      "Content-Based (TF-IDF) Results:\n",
      "  RMSE: 4.7353\n",
      "  MAE:  3.7583\n"
     ]
    }
   ],
   "source": [
    "# Content-based predictions:\n",
    "# For each test rating, find jokes the user liked and recommend similar jokes\n",
    "print(\"Making content-based predictions...\")\n",
    "cb_predictions = []\n",
    "\n",
    "for _, row in test_df.iterrows():\n",
    "    user_id = row['user']\n",
    "    item_id = int(row['item'])\n",
    "\n",
    "    # Get user's training ratings\n",
    "    user_train = train_df[train_df['user'] == user_id]\n",
    "\n",
    "    if len(user_train) == 0:\n",
    "        # Cold start: use global mean\n",
    "        cb_predictions.append(train_df['rating'].mean())\n",
    "        continue\n",
    "\n",
    "    # Weight user's ratings by joke similarity\n",
    "    similarities = joke_similarity[item_id]\n",
    "    weighted_sum = 0\n",
    "    weight_total = 0\n",
    "\n",
    "    for _, train_row in user_train.iterrows():\n",
    "        train_item = int(train_row['item'])\n",
    "        train_rating = train_row['rating']\n",
    "        similarity = similarities[train_item]\n",
    "\n",
    "        if similarity > 0:\n",
    "            weighted_sum += similarity * train_rating\n",
    "            weight_total += similarity\n",
    "\n",
    "    if weight_total > 0:\n",
    "        cb_predictions.append(weighted_sum / weight_total)\n",
    "    else:\n",
    "        cb_predictions.append(train_df['rating'].mean())\n",
    "\n",
    "cb_predictions = np.array(cb_predictions)\n",
    "\n",
    "rmse_cb = root_mean_squared_error(test_df['rating'], cb_predictions)\n",
    "mae_cb = mean_absolute_error(test_df['rating'], cb_predictions)\n",
    "\n",
    "print(f\"\\nContent-Based (TF-IDF) Results:\")\n",
    "print(f\"  RMSE: {rmse_cb:.4f}\")\n",
    "print(f\"  MAE:  {mae_cb:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine what TF-IDF considers \"similar\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Joke 0: A man visits the doctor. The doctor says \"I have bad news for you.You have cancer and Alzheimer's disease\". The man replies \"Well,thank God I don't have cancer!\"\n",
      "\n",
      "Top 3 most similar jokes by TF-IDF:\n",
      "\n",
      "1. Joke 86 (similarity: 0.745)\n",
      "   A man, recently completing a routine physical examination receives a phone call from his doctor. The doctor says, \"I have some good news and some bad news.\" The man says, \"OK, give me the good news first.\" The doctor says, \"The good news is, you have 24 hours to live.\" The man replies, \"Shit! That's the good news? Then what's the bad news?\" The doctor says, \"The bad news is, I forgot to call you yesterday.\"...\n",
      "\n",
      "2. Joke 87 (similarity: 0.646)\n",
      "   A Czechoslovakian man felt his eyesight was growing steadily worse, and felt it was time to go see an optometrist. The doctor started with some simple testing, and showed him a standard eye chart with letters of diminishing size: CRKBNWXSKZY. . . \"Can you read this?\" the doctor asked. \"Read it?\" the Czech answered. \"Doc, I know him!\"...\n",
      "\n",
      "3. Joke 67 (similarity: 0.414)\n",
      "   A man piloting a hot air balloon discovers he has wandered off course and is hopelessly lost. He descends to a lower altitude and locates a man down on the ground. He lowers the balloon further and shouts \"Excuse me, can you tell me where I am?\" The man below says: \"Yes, you're in a hot air balloon, about 30 feet above this field.\" \"You must work in Information Technology,\" says the balloonist. \"Yes I do,\" replies the man. \"And how did you know that?\" \"Well,\" says the balloonist, \"what you told me is technically correct, but of no use to anyone.\" The man below says, \"You must work in management.\" \"I do,\" replies the balloonist, \"how did you know?\" \"Well,\" says the man, \"you don't know where you are, or where you're going, but you expect my immediate help. You're in the same position you were before we met, but now it's my fault!\"...\n"
     ]
    }
   ],
   "source": [
    "# Show similar jokes by TF-IDF\n",
    "example_id = 0\n",
    "print(f\"\\nJoke {example_id}: {jokes_df.iloc[example_id]['joke_text']}\")\n",
    "\n",
    "similarities = joke_similarity[example_id]\n",
    "similar_indices = np.argsort(similarities)[::-1][1:4]  # Top 3 (excluding self)\n",
    "\n",
    "print(f\"\\nTop 3 most similar jokes by TF-IDF:\")\n",
    "for rank, idx in enumerate(similar_indices, 1):\n",
    "    print(f\"\\n{rank}. Joke {idx} (similarity: {similarities[idx]:.3f})\")\n",
    "    print(f\"   {jokes_df.iloc[idx]['joke_text']}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Are the \"similar\" jokes actually funny in the same way? What does TF-IDF capture about jokes, and what does it miss?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's explore what words appear in funny vs unfunny jokes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 funniest jokes:\n",
      "\n",
      "Joke 49 (rating: +3.67):\n",
      "  A guy goes into confession and says to the priest, \"Father, I'm 80 years old, widower, with 11 grandchildren. Last night I met two beautiful flight attendants. They took me home and I made love to both of them. Twice.\" The priest said: \"Well, my son, when was the last time you were in confession?\" \"Never Father, I'm Jewish.\" \"So then, why are you telling me?\" \"I'm telling everybody.\"\n",
      "\n",
      "Joke 88 (rating: +3.57):\n",
      "  A radio conversation of a US naval ship with Canadian authorities ... Americans: Please divert your course 15 degrees to the North to avoid a collision. Canadians: Recommend you divert YOUR course 15 degrees to the South to avoid a collision. Americans: This is the Captain of a US Navy ship. I say again, divert YOUR course. Canadians: No. I say again, you divert YOUR course. Americans: This is the aircraft carrier USS LINCOLN, the second largest ship in the United States' Atlantic Fleet. We are accompanied by three destroyers, three cruisers and numerous support vessels. I demand that you change your course 15 degrees north, that's ONE FIVE DEGREES NORTH, or counter-measures will be undertaken to ensure the safety of this ship. Canadians: This is a lighthouse. Your call.\n",
      "\n",
      "Joke 35 (rating: +3.31):\n",
      "  A guy walks into a bar, orders a beer and says to the bartender, \"Hey, I got this great Polish Joke...\" The barkeep glares at him and says in a warning tone of voice: \"Before you go telling that joke you better know that I'm Polish, both bouncers are Polish and so are most of my customers\" \"Okay\" says the customer,\"I'll tell it very slowly.\"\n",
      "\n",
      "Joke 26 (rating: +3.19):\n",
      "  Clinton returns from a vacation in Arkansas and walks down the steps of Air Force One with two pigs under his arms. At the bottom of the steps, he says to the honor guardsman, \"These are genuine Arkansas Razor-Back Hogs. I got this one for Chelsea and this one for Hillary.\" The guardsman replies, \"Nice trade, Sir.\"\n",
      "\n",
      "Joke 31 (rating: +3.16):\n",
      "  A man arrives at the gates of heaven. St. Peter asks, \"Religion?\" The man says, \"Methodist.\" St. Peter looks down his list, and says, \"Go to room 24, but be very quiet as you pass room 8.\" Another man arrives at the gates of heaven. \"Religion?\" \"Baptist.\" \"Go to room 18, but be very quiet as you pass room 8.\" A third man arrives at the gates. \"Religion?\" \"Jewish.\" \"Go to room 11, but be very quiet as you pass room 8.\" The man says, \"I can understand there being different rooms for different religions, but why must I be quiet when I pass room 8?\" St. Peter tells him, \"Well the Catholics are in room 8, and they think they're the only ones here.\n",
      "\n",
      "\n",
      "Top 5 worst jokes:\n",
      "\n",
      "Joke 12 (rating: -1.76):\n",
      "  They asked the Japanese visitor if they have elections in his country. \"Every Morning\" he answers.\n",
      "\n",
      "Joke 56 (rating: -1.99):\n",
      "  Why are there so many Jones's in the phone book? Because they all have phones.\n",
      "\n",
      "Joke 43 (rating: -2.11):\n",
      "  A horse walks into a bar. Bartender says: \"So, why the long face?\"\n",
      "\n",
      "Joke 15 (rating: -3.10):\n",
      "  Q. What is orange and sounds like a parrot? A. A carrot.\n",
      "\n",
      "Joke 57 (rating: -3.83):\n",
      "  How many teddybears does it take to change a lightbulb? It takes only one teddybear, but it takes a whole lot of lightbulbs.\n"
     ]
    }
   ],
   "source": [
    "# Merge jokes with their mean ratings\n",
    "joke_stats = ratings_df.groupby('item')['rating'].agg(['mean', 'count'])\n",
    "joke_stats = joke_stats.sort_values('mean', ascending=False)\n",
    "jokes_with_ratings = jokes_df.merge(\n",
    "    joke_stats, left_on='joke_id', right_index=True\n",
    ")\n",
    "\n",
    "# Sort by rating to get actual funniest/worst\n",
    "jokes_with_ratings = jokes_with_ratings.sort_values('mean', ascending=False)\n",
    "\n",
    "# Show funniest and worst jokes\n",
    "print(\"Top 5 funniest jokes:\")\n",
    "for i, row in jokes_with_ratings.head(5).iterrows():\n",
    "    print(f\"\\nJoke {row['joke_id']} (rating: {row['mean']:+.2f}):\")\n",
    "    print(f\"  {row['joke_text']}\")\n",
    "\n",
    "print(\"\\n\\nTop 5 worst jokes:\")\n",
    "for i, row in jokes_with_ratings.tail(5).iterrows():\n",
    "    print(f\"\\nJoke {row['joke_id']} (rating: {row['mean']:+.2f}):\")\n",
    "    print(f\"  {row['joke_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use TF-IDF with Ridge Regression to find words associated with humor:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Build word-level TF-IDF features\n",
    "\n",
    "First, import Ridge Regression and build TF-IDF features for individual words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (100, 100)\n",
      "Target ratings shape: (100,)\n"
     ]
    }
   ],
   "source": [
    "# Use TF-IDF + Ridge Regression to find words associated with humor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "# Build TF-IDF features for all jokes (individual words only)\n",
    "vectorizer_words = TfidfVectorizer(\n",
    "    max_features=100,      # Keep only top 100 words\n",
    "    stop_words='english',  # Remove common words like \"the\", \"a\", \"is\"\n",
    "    ngram_range=(1, 1),    # Single words only (unigrams)\n",
    "    min_df=2               # Word must appear in at least 2 jokes\n",
    ")\n",
    "\n",
    "X_words = vectorizer_words.fit_transform(jokes_with_ratings['joke_text'])\n",
    "y_ratings = jokes_with_ratings['mean'].values\n",
    "\n",
    "print(f\"TF-IDF matrix shape: {X_words.shape}\")\n",
    "print(f\"Target ratings shape: {y_ratings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF (Term Frequency-Inverse Document Frequency) converts text into numbers. Each joke becomes a vector of 100 numbers representing how important each word is in that joke."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Train Ridge Regression on words\n",
    "\n",
    "Now train a Ridge Regression model to predict joke ratings from words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word-based rating prediction R^2: 0.6059\n",
      "Best alpha: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Train Ridge regression to predict ratings from words\n",
    "# RidgeCV automatically selects the best regularization strength\n",
    "ridge = RidgeCV(alphas=[0.01, 0.1, 1.0, 10.0, 100.0])\n",
    "ridge.fit(X_words, y_ratings)\n",
    "\n",
    "print(f\"\\nWord-based rating prediction R^2: {ridge.score(X_words, y_ratings):.4f}\")\n",
    "print(f\"Best alpha: {ridge.alpha_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R² score tells us how well words predict joke ratings. A score near 1.0 means words are very predictive; near 0 means they're not helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Analyze word coefficients\n",
    "\n",
    "Examine which words are associated with funny vs unfunny jokes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 words associated with FUNNY jokes:\n",
      "  course              : +1.6628\n",
      "  says                : +1.5402\n",
      "  looking             : +1.2219\n",
      "  woman               : +1.2105\n",
      "  said                : +1.1747\n",
      "  father              : +1.1036\n",
      "  look                : +1.0598\n",
      "  asks                : +1.0459\n",
      "  got                 : +1.0278\n",
      "  president           : +1.0103\n",
      "\n",
      "Top 10 words associated with UNFUNNY jokes:\n",
      "  like                : -1.2370\n",
      "  asked               : -1.1257\n",
      "  change              : -0.9933\n",
      "  did                 : -0.8436\n",
      "  bar                 : -0.7742\n",
      "  start               : -0.6713\n",
      "  want                : -0.6079\n",
      "  lightbulb           : -0.5703\n",
      "  person              : -0.5586\n",
      "  sleep               : -0.5387\n"
     ]
    }
   ],
   "source": [
    "# Get coefficients (positive = associated with funny, negative = unfunny)\n",
    "coefs = ridge.coef_\n",
    "feature_names = vectorizer_words.get_feature_names_out()\n",
    "sorted_indices = np.argsort(coefs)\n",
    "\n",
    "print(\"\\nTop 10 words associated with FUNNY jokes:\")\n",
    "for idx in sorted_indices[-10:][::-1]:\n",
    "    print(f\"  {feature_names[idx]:20s}: {coefs[idx]:+.4f}\")\n",
    "\n",
    "print(\"\\nTop 10 words associated with UNFUNNY jokes:\")\n",
    "for idx in sorted_indices[:10]:\n",
    "    print(f\"  {feature_names[idx]:20s}: {coefs[idx]:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive coefficients mean the word appears more in highly-rated jokes; negative coefficients mean it appears more in poorly-rated jokes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Build bigram features\n",
    "\n",
    "Now try bigrams (two-word phrases) instead of individual words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram TF-IDF matrix shape: (100, 41)\n"
     ]
    }
   ],
   "source": [
    "# Build TF-IDF features for bigrams (two-word phrases)\n",
    "vectorizer_bigrams = TfidfVectorizer(\n",
    "    max_features=100,\n",
    "    stop_words='english',\n",
    "    ngram_range=(2, 2),  # Only two-word phrases\n",
    "    min_df=2\n",
    ")\n",
    "\n",
    "X_bigrams = vectorizer_bigrams.fit_transform(jokes_with_ratings['joke_text'])\n",
    "print(f\"Bigram TF-IDF matrix shape: {X_bigrams.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigrams can capture phrases like \"knock knock\" or \"chicken cross\" that might be more meaningful than individual words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Train and evaluate bigram model\n",
    "\n",
    "Train and evaluate the bigram model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bigram-based rating prediction R^2: 0.3097\n",
      "\n",
      "Top 10 bigrams associated with FUNNY jokes:\n",
      "  man says                      : +1.4749\n",
      "  beer says                     : +1.4341\n",
      "  united states                 : +1.1840\n",
      "  ll just                       : +1.0667\n",
      "  orders beer                   : +1.0667\n",
      "  shook head                    : +1.0240\n",
      "  engineer said                 : +0.8244\n",
      "  man woman                     : +0.8205\n",
      "  years old                     : +0.7771\n",
      "  son time                      : +0.7771\n",
      "\n",
      "Top 10 bigrams associated with UNFUNNY jokes:\n",
      "  does change                   : -1.1802\n",
      "  walks bar                     : -0.9251\n",
      "  did hear                      : -0.9110\n",
      "  light bulb                    : -0.6185\n",
      "  change lightbulb              : -0.5216\n",
      "  does screw                    : -0.3671\n",
      "  screw light                   : -0.3671\n",
      "  year old                      : -0.2769\n",
      "  know difference               : -0.1885\n",
      "  replies just                  : -0.1808\n"
     ]
    }
   ],
   "source": [
    "# Train Ridge regression with bigrams\n",
    "ridge_bigrams = RidgeCV(alphas=[0.01, 0.1, 1.0, 10.0, 100.0])\n",
    "ridge_bigrams.fit(X_bigrams, y_ratings)\n",
    "\n",
    "print(f\"\\nBigram-based rating prediction R^2: {ridge_bigrams.score(X_bigrams, y_ratings):.4f}\")\n",
    "\n",
    "# Show top bigrams\n",
    "coefs_bigrams = ridge_bigrams.coef_\n",
    "features_bigrams = vectorizer_bigrams.get_feature_names_out()\n",
    "sorted_indices_bigrams = np.argsort(coefs_bigrams)\n",
    "\n",
    "print(\"\\nTop 10 bigrams associated with FUNNY jokes:\")\n",
    "for idx in sorted_indices_bigrams[-10:][::-1]:\n",
    "    print(f\"  {features_bigrams[idx]:30s}: {coefs_bigrams[idx]:+.4f}\")\n",
    "\n",
    "print(\"\\nTop 10 bigrams associated with UNFUNNY jokes:\")\n",
    "for idx in sorted_indices_bigrams[:10]:\n",
    "    print(f\"  {features_bigrams[idx]:30s}: {coefs_bigrams[idx]:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Look at the funniest vs worst jokes. Can you identify patterns? Are funny jokes longer stories while unfunny ones are short Q&A puns? Can word counts alone predict humor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A8. Compare models with a bar chart\n",
    "\n",
    "Visualize the performance of all four models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = ['Baseline', 'Content-Based', 'KNN', 'SVD']\n",
    "rmse_values = [rmse_baseline, rmse_cb, rmse_knn, rmse_svd]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(models, rmse_values, color=['gray', 'orange', 'lightblue', 'lightgreen'],\n",
    "        edgecolor='black', alpha=0.7)\n",
    "plt.ylabel('RMSE (Lower is Better)')\n",
    "plt.title('Model Comparison on Jester Dataset')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(rmse_values):\n",
    "    plt.text(i, v + 0.05, f'{v:.4f}', ha='center', va='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Which model performs best? Which model is worst?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A9. Analyze joke ratings\n",
    "\n",
    "The SVD model is already trained on the full dataset. Let's analyze joke ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 funniest jokes (highest average rating):\n",
      "  1. Joke 49: avg rating = +3.67 (24972 ratings)\n",
      "  2. Joke 88: avg rating = +3.57 (9564 ratings)\n",
      "  3. Joke 35: avg rating = +3.31 (24965 ratings)\n",
      "  4. Joke 26: avg rating = +3.19 (24904 ratings)\n",
      "  5. Joke 31: avg rating = +3.16 (24948 ratings)\n",
      "\n",
      "Top 5 worst jokes (lowest average rating):\n",
      "  1. Joke 12: avg rating = -1.76 (24981 ratings)\n",
      "  2. Joke 56: avg rating = -1.99 (15973 ratings)\n",
      "  3. Joke 43: avg rating = -2.11 (16177 ratings)\n",
      "  4. Joke 15: avg rating = -3.10 (24975 ratings)\n",
      "  5. Joke 57: avg rating = -3.83 (15553 ratings)\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean ratings per joke\n",
    "joke_stats = ratings_df.groupby('item')['rating'].agg(['mean', 'count'])\n",
    "joke_stats = joke_stats.sort_values('mean', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 5 funniest jokes (highest average rating):\")\n",
    "for idx, (joke_id, row) in enumerate(joke_stats.head(5).iterrows(), 1):\n",
    "    print(f\"  {idx}. Joke {joke_id}: avg rating = {row['mean']:+.2f} ({int(row['count'])} ratings)\")\n",
    "\n",
    "print(f\"\\nTop 5 worst jokes (lowest average rating):\")\n",
    "for idx, (joke_id, row) in enumerate(joke_stats.tail(5).iterrows(), 1):\n",
    "    print(f\"  {idx}. Joke {joke_id}: avg rating = {row['mean']:+.2f} ({int(row['count'])} ratings)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A10. Generate personalized joke recommendations\n",
    "\n",
    "Use the SVD model to recommend jokes for a specific user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 joke recommendations for User 0:\n",
      "  1. Joke 88: predicted rating = +1.43\n",
      "  2. Joke 70: predicted rating = +1.06\n",
      "  3. Joke 79: predicted rating = +0.74\n",
      "  4. Joke 71: predicted rating = +0.65\n",
      "  5. Joke 75: predicted rating = +0.36\n",
      "  6. Joke 92: predicted rating = +0.28\n",
      "  7. Joke 80: predicted rating = -0.00\n",
      "  8. Joke 82: predicted rating = -0.01\n",
      "  9. Joke 72: predicted rating = -0.53\n",
      "  10. Joke 86: predicted rating = -0.64\n"
     ]
    }
   ],
   "source": [
    "# Get recommendations for user 0\n",
    "user_id = 0\n",
    "\n",
    "# Get user's predictions from the reconstructed ratings matrix\n",
    "user_predictions = predicted_ratings[user_id, :]\n",
    "\n",
    "# Find items the user hasn't rated yet\n",
    "user_rated_items = ratings_df[ratings_df['user'] == user_id]['item'].values\n",
    "unrated_items = [i for i in range(n_jokes) if i not in user_rated_items]\n",
    "\n",
    "# Get predictions for unrated items and sort\n",
    "unrated_predictions = [(item, user_predictions[item]) for item in unrated_items]\n",
    "unrated_predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Show top 10\n",
    "print(f\"\\nTop 10 joke recommendations for User {user_id}:\")\n",
    "for i, (joke_id, pred_rating) in enumerate(unrated_predictions[:10], 1):\n",
    "    print(f\"  {i}. Joke {joke_id}: predicted rating = {pred_rating:+.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: If you were building a real joke app, how would you present these recommendations to users? Would you just show the top-rated jokes, or try to balance quality with diversity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B --- Implicit Feedback Comparison\n",
    "\n",
    "In Part A, we used **explicit feedback** (users rated jokes). Now we'll explore **implicit feedback**, where we only observe user behavior (clicks, views) without explicit ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B1. Import the implicit library\n",
    "\n",
    "Import the `implicit` library (you already installed it in Preparation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import implicit.als\n",
    "import implicit.evaluation\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B2. Load MovieLens for implicit feedback\n",
    "\n",
    "We'll use MovieLens 100K, but convert it to implicit feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MovieLens 100K dataset\n",
    "print(\"Loading MovieLens 100K dataset...\")\n",
    "url = \"https://files.grouplens.org/datasets/movielens/ml-100k/u.data\"\n",
    "ml_data = pd.read_csv(url, sep='\\t', names=['user', 'item', 'rating', 'timestamp'])\n",
    "\n",
    "# Convert to 0-indexed\n",
    "ml_data['user'] = ml_data['user'] - 1\n",
    "ml_data['item'] = ml_data['item'] - 1\n",
    "\n",
    "n_users_ml = ml_data['user'].nunique()\n",
    "n_items_ml = ml_data['item'].nunique()\n",
    "\n",
    "print(f\"MovieLens 100K:\")\n",
    "print(f\"  Users: {n_users_ml}\")\n",
    "print(f\"  Movies: {n_items_ml}\")\n",
    "print(f\"  Ratings: {len(ml_data):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B3. Convert to implicit interactions\n",
    "\n",
    "Convert ratings to binary interactions: any rating ≥ 4 means \"watched and liked.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to implicit interactions (rating >= 4 means positive interaction)\n",
    "implicit_data = ml_data[ml_data['rating'] >= 4.0].copy()\n",
    "\n",
    "print(f\"Positive interactions (rating >= 4): {len(implicit_data):,}\")\n",
    "print(f\"This is {len(implicit_data)/len(ml_data)*100:.1f}% of all ratings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B4. Create sparse user-item matrix\n",
    "\n",
    "Build the sparse matrix that the `implicit` library expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sparse user-item matrix\n",
    "user_item_matrix = csr_matrix(\n",
    "    (np.ones(len(implicit_data)),\n",
    "     (implicit_data['user'].values, implicit_data['item'].values)),\n",
    "    shape=(n_users_ml, n_items_ml)\n",
    ")\n",
    "\n",
    "print(f\"Matrix shape: {user_item_matrix.shape}\")\n",
    "print(f\"Sparsity: {100 * (1 - user_item_matrix.nnz / (n_users_ml * n_items_ml)):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B5. Train ALS model\n",
    "\n",
    "Train an Alternating Least Squares model on the implicit data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_als = implicit.als.AlternatingLeastSquares(\n",
    "    factors=50,\n",
    "    regularization=0.01,\n",
    "    iterations=20,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Note: implicit library expects item-user matrix (transposed!)\n",
    "model_als.fit(user_item_matrix.T)\n",
    "print(\"ALS training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B6. Evaluate with ranking metrics\n",
    "\n",
    "For implicit data, we can't use RMSE (there are no rating values!). Instead, we use ranking metrics like Precision@K, which measures: \"Of the top K recommendations, how many were actually relevant?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Split data into train and test\n",
    "\n",
    "First, split the data into train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split implicit data into train/test for evaluation\n",
    "# For each user, hold out 20% of their interactions for testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(implicit_data, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Train interactions: {len(train_data):,}\")\n",
    "print(f\"Test interactions: {len(test_data):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create sparse matrices\n",
    "\n",
    "Now create separate sparse matrices for training and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train matrix (used for model training)\n",
    "train_user_item = csr_matrix(\n",
    "    (np.ones(len(train_data)),\n",
    "     (train_data['user'].values, train_data['item'].values)),\n",
    "    shape=(n_users_ml, n_items_ml)\n",
    ")\n",
    "\n",
    "# Create test matrix (held out for evaluation)\n",
    "test_user_item = csr_matrix(\n",
    "    (np.ones(len(test_data)),\n",
    "     (test_data['user'].values, test_data['item'].values)),\n",
    "    shape=(n_users_ml, n_items_ml)\n",
    ")\n",
    "\n",
    "print(f\"Train matrix shape: {train_user_item.shape}\")\n",
    "print(f\"Test matrix shape: {test_user_item.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sparse matrix format stores only the non-zero entries (user-item interactions), which is memory-efficient for large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Re-train ALS model\n",
    "\n",
    "Re-train the ALS model on training data only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-train model on training data only\n",
    "model_als = implicit.als.AlternatingLeastSquares(\n",
    "    factors=50,           # Latent factors (like SVD)\n",
    "    regularization=0.01,  # Prevent overfitting\n",
    "    iterations=20,        # How many training iterations\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Note: implicit library expects item-user matrix (transposed!)\n",
    "model_als.fit(train_user_item.T)\n",
    "print(\"ALS training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Evaluate with Precision@K\n",
    "\n",
    "Evaluate using Precision@10 metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set using Precision@K\n",
    "# Precision@10 = \"Of the top 10 recommendations, how many were actually relevant?\"\n",
    "# Note: precision_at_k may have compatibility issues with some scipy versions\n",
    "try:\n",
    "    precision = implicit.evaluation.precision_at_k(\n",
    "        model_als, train_user_item, test_user_item, K=10,\n",
    "        show_progress=False, num_threads=1\n",
    "    )\n",
    "    print(f\"\\nPrecision@10: {precision:.4f}\")\n",
    "    print(f\"Interpretation: {precision*100:.1f}% of top-10 recommendations are relevant\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nNote: Precision evaluation skipped due to library compatibility issue\")\n",
    "    print(f\"Error: {type(e).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B7. Get recommendations from implicit model\n",
    "\n",
    "Generate recommendations for a user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_idx = 0  # First user\n",
    "\n",
    "# Get recommendations (use training data to filter out items already seen)\n",
    "item_ids, scores = model_als.recommend(user_idx, train_user_item[user_idx], N=10)\n",
    "\n",
    "print(f\"\\nTop 10 recommendations for User {user_idx}:\")\n",
    "for i, (item_idx, score) in enumerate(zip(item_ids, scores), 1):\n",
    "    print(f\"  {i}. Movie {item_idx}: confidence score = {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: How do these \"confidence scores\" differ from the predicted ratings in Part A?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B8. Compare explicit vs implicit approaches\n",
    "\n",
    "Create a comparison table in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame({\n",
    "    'Aspect': ['Data Type', 'Signal Strength', 'Data Volume',\n",
    "               'Goal', 'Evaluation', 'Example'],\n",
    "    'Explicit (Jester)': ['Star ratings (-10 to +10)', 'Strong', 'Moderate',\n",
    "                          'Predict rating value', 'RMSE, MAE', 'Netflix ratings'],\n",
    "    'Implicit (MovieLens)': ['Binary (watched/not)', 'Weak', 'Abundant',\n",
    "                             'Rank by preference', 'Precision@K', 'YouTube views']\n",
    "})\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Easy Extensions (Optional)\n",
    "\n",
    "If you have time, try this personalized recommendation exercise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rate some jokes and get recommendations\n",
    "\n",
    "Let's make this personal! Rate a few jokes from the database and get recommendations for jokes you might like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Rate some jokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a few random jokes for you to rate\n",
    "import random\n",
    "\n",
    "print(\"Let's find jokes you'll like! Rate these jokes on a scale from -10 to +10:\")\n",
    "print(\"(-10 = terrible, 0 = neutral, +10 = hilarious)\\n\")\n",
    "\n",
    "# Select 5 random jokes from the dataset\n",
    "random_joke_ids = random.sample(range(n_jokes), 5)\n",
    "your_ratings = {}\n",
    "\n",
    "for i, joke_id in enumerate(random_joke_ids, 1):\n",
    "    joke_text = jokes_df[jokes_df['joke_id'] == joke_id]['joke_text'].values[0]\n",
    "    print(f\"--- Joke {i}/5 (ID: {joke_id}) ---\")\n",
    "    print(joke_text)\n",
    "    print()\n",
    "\n",
    "    # Get rating from user\n",
    "    while True:\n",
    "        try:\n",
    "            rating = float(input(f\"Your rating (-10 to +10): \"))\n",
    "            if -10 <= rating <= 10:\n",
    "                your_ratings[joke_id] = rating\n",
    "                break\n",
    "            else:\n",
    "                print(\"Please enter a number between -10 and +10\")\n",
    "        except ValueError:\n",
    "            print(\"Please enter a valid number\")\n",
    "    print()\n",
    "\n",
    "print(\"\\nThanks for rating! Now let's find jokes you'll love...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Generate personalized recommendations\n",
    "\n",
    "Now use the SVD model to predict ratings for all unrated jokes and recommend the best ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new user vector based on your ratings\n",
    "# Start with a zero vector\n",
    "your_user_vector = np.zeros(n_jokes)\n",
    "for joke_id, rating in your_ratings.items():\n",
    "    your_user_vector[joke_id] = rating\n",
    "\n",
    "# Project your ratings into the latent space using SVD\n",
    "your_factors = svd_model.transform(your_user_vector.reshape(1, -1))\n",
    "\n",
    "# Predict ratings for all jokes\n",
    "your_predictions = your_factors @ item_factors.T\n",
    "your_predictions = your_predictions[0]  # Flatten to 1D array\n",
    "\n",
    "# Find unrated jokes and sort by predicted rating\n",
    "unrated_jokes = [j for j in range(n_jokes) if j not in your_ratings]\n",
    "joke_predictions = [(j, your_predictions[j]) for j in unrated_jokes]\n",
    "joke_predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Show top 5 recommendations\n",
    "print(\"Based on your ratings, here are 5 jokes we think you'll love:\\n\")\n",
    "for i, (joke_id, pred_rating) in enumerate(joke_predictions[:5], 1):\n",
    "    joke_text = jokes_df[jokes_df['joke_id'] == joke_id]['joke_text'].values[0]\n",
    "    print(f\"--- Recommendation {i} (Joke {joke_id}, predicted rating: {pred_rating:+.2f}) ---\")\n",
    "    print(joke_text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Do the recommended jokes match your sense of humor? If you rated them, how close were the predictions to your actual ratings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion Questions (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Cold Start Problem**: How would you handle a brand new user who has never rated any jokes? What about a new joke that no one has rated yet?\n",
    "\n",
    "2. **Explicit vs Implicit**: YouTube uses implicit feedback (watch time, clicks) instead of asking users to rate videos. What are the advantages and disadvantages of this approach?\n",
    "\n",
    "3. **Ethics**: The lecture discussed how YouTube optimizes for engagement (watch time) while Netflix optimizes for satisfaction. How might this difference affect what content gets recommended? Can you think of potential harms from optimizing purely for engagement?\n",
    "\n",
    "4. **Filter Bubbles**: If a recommender system only shows you content similar to what you've liked before, what problems might this cause? How would you modify a recommender system to promote diversity while still being useful?\n",
    "\n",
    "5. **Evaluation Metrics**: We used RMSE for explicit ratings and Precision@K for implicit feedback. Why are these different? What does each metric actually measure?\n",
    "\n",
    "6. **Real-World Application**: If you were building a recommender system for a streaming music service (like Spotify), would you use explicit ratings, implicit feedback, or both? Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extension Challenges (Optional)\n",
    "\n",
    "If you finish early, try these challenges:\n",
    "\n",
    "1. **Hybrid System**: Combine both SVD and KNN predictions by averaging their outputs. Does this perform better than either alone?\n",
    "\n",
    "2. **Temporal Patterns**: The Jester dataset may have timestamps. Can you detect whether joke preferences change over time?\n",
    "\n",
    "3. **User Similarity**: Find the most similar user to User 1 using Pearson correlation on their joke ratings. Do they have similar taste in jokes?\n",
    "\n",
    "4. **Item-Based CF**: We used user-based collaborative filtering (find similar users). Try item-based filtering (find similar jokes) by setting `user_based=False` in KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz questions\n",
    "\n",
    "As usual, carry on with some quiz questions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
